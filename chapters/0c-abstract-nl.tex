\begin{abstract*}
  De afgelopen jaren is het internet steeds meer gecentraliseerd geworden \citep{internet-report}. Dit heeft vele negatieve gevolgen, waaronder gedaalde concurrentie en een gebrek aan toegang tot persoonlijke gegevens \citep{big-tech-innovation, platform-monopolies}. Solid \citep{solid} is een nieuwe voorlopige W3C specificatie die dit probleem tracht op te lossen door het introduceren van datakluizen. Datakluizen zijn gedecentraliseerde opslagplaatsen voor data waar gegevens voor verschillende toepassingen worden bijgehouden. Op deze manier bewaart de gebruiker controle over zijn persoonlijke gegevens, en kan dezelfde data door verschillende diensten gebruikt worden.
  
  Deze datakluizen brengen een hoop mogelijkheden met zich mee, maar evenzeer technologische uitdagingen. Een van zo'n uitdagingen is veilige en beschermde gegevensaggregatie over verschillende datakluizen heen. Dergelijke aggregaties brengen privacyrisico's met zich mee, net als schaalbaarheidsproblemen. Deze thesis introduceert een middleware op het niveau van de server, die tracht deze problemen gedeeltelijk op te lossen dankzij het introduceren van twee nieuwe technologie{\"e}n. Deze technologie{\"e}n zijn privacy filters en een nieuw mechanisme voor toegangstokens dat gedecentraliseerde tokenafvaardiging ondersteunt.

  Privacy filters is een technologie die toelaat om meer granulariteit te bereiken in de privacy van gedeelde bronnen. Wanneer een verzoek gemaakt wordt selecteert de middleware automatisch een aantal transformaties die uitgevoerd worden op de verzochte bron. Dit gebeurt gebaseerd op een aantal contextuele parameters, zoals welke toepassing het verzoek verzonden heeft of wat het data type is van de verzochte bron. Om vervolgens een tokenmechanisme te bekomen dat gedecentraliseerde tokenafvaardiging ondersteunt onderzoekt deze thesis het gebruik van macaroons als nieuw tokenmechanisme binnen Solid. Macaroons ondersteunen niet alleen gedecentraliseerde tokenafvaardiging, maar zijn ook effici{\"e}nter om te genereren en verifi{\"e}n. Bovendien laten ze attestaties van derde partijen toe (\textit{third-party attestations}), wat een nuttige eigenschap is om datakluizen te bekomen die gedeeld worden door een groep gebruikers.
  
  De middleware die deze thesis voorstelt werd ge{\"e}valueerd op grond van drie gebruiksscenario's. Voor privacy filters hebben een aantal prestatie-experimenten aangetoond dat de overhead van de middleware toelaatbaar is voor kleinere bronnen. Het herschrijven van bronnen tot 300KB gebruikmakende van drie transformaties leidt tot een overhead van ongeveer 50\%. Echter, grotere bronnen (rond de 3MB) hebben een overhead die een vijfvoud wordt van de oorspronkelijke duur van het verzoek. Zodanig kan een effici{\"e}nter mechanisme voor het herschrijven van bronnen hier bruikbaar zijn, hoewel dit probleem kan verminderd worden door gebruik te maken van caches, of met behulp van voorberekeningen. Prestatie-experimenten die werden uitgevoerd op het genereren en verifi{\"e}ren van macaroons hebben aangetoond dat hier sterke prestatievoordelen aan vasthangen. De doorvoer voor het genereren en verifi{\"e}n van macaroons is respectievelijk zeven en elf maal groter dan het \acrshort{DPoP} systeem wanneer dit gebruik maakt van het ES256 algoritme. Ten slotte zijn er ook theoretische winsten voor gedecentraliseerde tokenafvaardiging, gezien dit mechanisme een verminderd aantal interacties nodig heeft voor het afvaardigen van een toegangstoken in vergelijking met een gecentraliseerd mechanisme zoals \acrshort{DPoP}.
\end{abstract*}