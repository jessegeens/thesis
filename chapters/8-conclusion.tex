\chapter{Conclusion}
\label{cha:conclusion}
\section{Overview}
The research question this dissertation aims to answer, posed in section \ref{sec:problem}, asks whether we can design a scalable middleware solution aimed at facilitating data aggregation in a secure and protected manner in a setting where data is distributed across various parties. To answer this question, such a middleware has been developed in the context of this dissertation. Three use cases have been employed to guide the design of the middleware, from which concrete requirements were also derived.  To guarantee the privacy-aspect of the middleware, a number of \acrlong{PETs} have been analyzed in this context. This analysis has led to a number of possible future research directions, which are discussed in the next section.

The middleware introduces two novel components, privacy filters and a new access token system. Privacy filters are a mechanism to dynamically rewrite resources based on contextual information from the request, to reduce attribute leakage to untrusted applications. Privacy filters provide granularity in the provided level of privacy by introducing privacy levels, which map the requested level of privacy to a concrete set of privacy-enhancing transformations. In addition, this dissertation suggests using macaroons as a novel access token mechanism. Macaroons support decentralized delegation, which is a crucial part of a scalable aggregation system. Furthermore, macaroons are also more efficient to generate and verify than the currently used \gls{DPoP} token mechanism. Lastly, macaroons support third-party attestations, which is a useful property for enabling group vaults.

The middleware solution proposed in this dissertation has also been thoroughly evaluated. This evaluation has demonstrated that the laid out requirements have, for the most part, been fulfilled. In particular, the middleware supports automatically selecting the right \gls{PETs} across different data schemes. Implementing privacy filters as an extension of the \gls{CSS} has made the middleware also very extensible. However, there are limitations on the performance of privacy filters for large resources, and the testability requirement has not been completely fulfilled as the developed prototype does not come with an additional test suite. 

Additionally, the evaluation has demonstrated that macaroons bring a number of performance improvements. These improvements are both practical with an increased throughput of token generation and verification, as well as theoretical with a decreased interaction cost necessary for delegating access tokens. Concretely, the throughput of generating tokens compared to \gls{DPoP} with the ES256 algorithm has increased more than seven-fold by using macaroons, while the throughput of verifying the tokens increased more than eleven-fold. The number of interactions for delegating an access token has decreased by a factor $2(\delta + (\pi_1 - \pi_2))$, where $\delta$ is the cost of an interaction between a service and the token endpoint, and $\pi_1 - \pi_2$ is the performance difference between \gls{DPoP} and macaroons for generating access tokens.

%To conclude, the main results of this dissertation are the following. Firstly, this dissertation presented a mechanism for enabling more fine-grained privacy controls, which is feasible for smaller resources but needs a more efficient data structure (or a caching or precomputation mechanism) to be usable for larger resources. Furthermore, this dissertation has illustrated the feasibility of using macaroons as a novel access token mechanism, as it comes with serious performance improvements, enables decentralized delegation of access tokens and allows for a natural way to realize group vaults in a decentralized manner through third-party attestations. Finally, 

\section{Future work}
\label{sec:future-work}
\begin{futurework}\label{fw:homomorphic-encryption}
\textbf{\,---\, Homomorphic encryption in Solid} Homomorphic encryption is an encryption technology that allows for mathematical operations on the ciphertext. It was discussed in section \ref{sec:enc-db}. Homomorphic encryption is a computationally expensive yet promising technology which allows mathematical operations to be performed on encrypted data. This makes it a very interesting technology to make the Solid specification more privacy-friendly and robust against data leaks when data aggregations are performed. For example, a possible use case could be an application that collects salaries from a number of pods, and then gives back an encrypted answer to each pod containing the average salary. In this way, interesting insights can be gained without sacrificing personal information. However, this method also lacks somewhat in the need for a centralized party that performs the aggregation \,---\, it is not fully decentralized. Whether this is problematic depends heavily on the concrete use case. Additionally, some coordination is needed between the pods beforehand to make sure that the necessary data is encrypted in the same manner. Future research could investigate a potential implementation of a secure data aggregator for Solid based on homomorphic encryption schemes.
\end{futurework}

\begin{futurework}\label{fw:mpc}
\textbf{\,---\, \gls{MPC} in Solid} \acrlong{MPC} is a cryptographic technique that allows for securely performing computations on data, without sharing this data between parties. While at first glance this might seem similar to FW \ref{fw:homomorphic-encryption}, there are some major differences. Firstly, in the case of the homomorphic encryption, there was a single central party that performed the computation. In the case of \gls{MPC}, though, this computation is entirely decentralized and happens on the parties themselves; data is never shared or exposed. 
This has many advantages as the \gls{MPC} scenario clearly fits better in the decentralized nature of Solid. Nevertheless, there are disadvantages as well. In the homomorphic encryption scenario only few modifications to the Solid protocol would be required. The bulk of the work would happen in the party that performed the aggregation by requesting encrypted data from multiple pods. However, as \gls{MPC} does not share any data and computations happen locally, an implementation of \gls{MPC} in Solid would require many additions to the Solid protocol. Developing an architecture an improved specification for Solid could thus be very interesting future research, with many possible applications.
\end{futurework}

\newpage
\begin{futurework}\label{fw:privacy-levels}
\textbf{\,---\, Privacy levels} Currently, this dissertation has proposed a number of so-called \textit{privacy levels} (see section \ref{sec:privacylevels}) which form a granular way to determine how much data may be handed over to an untrusted application. However, this was only a practical proposal lacking a rigorous definition. Future research could investigate possible ways to define privacy levels more rigorously, for example by finding some sort of leakage metric that determines the maximum leakage of data under a certain privacy level.
\end{futurework}

\begin{futurework}\label{fw:abe}
\textbf{\,---\, \acrlong{ABE}}
Section \ref{sec:attacker-model} highlighted a honest-but-curious adversary model where applications are not completely trusted. However, an attacker model where the roles are reversed is also possible. This would be a scenario where the applications are highly trusted, but the Solid pod is stored at a third party and there is no way to verify that there are no vulnerabilities in the server source code. As such, this implies an active attacker that can deviate from the protocol and actively tries to bypass the Solid server's authentication and authorization mechanisms. Effectively, this means that the attacker can access resources to which it should not have access according to the \gls{ACL}s as these resources can be stored on-disk. Should an attacker breach the server (for exampling, getting SSH access in some way), then he can read all resources stored on the server. 

A good solution to this problem would be encryption, which would obscure the data stored in the Solid pod, and only parties with a correct key could access the data. However, in the decentralized context of Solid, this is hard to achieve. Multiple applications need to access the same data, and access policies for resources can be complex. In addition, these access policies must also be dynamic, meaning that it must be possible for a user to withdraw an application's access to a resource. Using traditional encryption methods will quickly lead to decidedly complex key management. By mapping applications to attributes and using \acrlong{CP-ABE} to encrypt resources with an access policy, this problem may be solved. As such, researching \gls{CP-ABE} for securely storing data on Solid pods and sharing it with applications may be useful future research.

%A naive approach could use symmetric key encryption because of the high speed and computational efficiency, but this approach is lacking in this decentralized context as key management would be problematic. Since many access policies are possible, a key per policy would be required, which comes with a lot of overhead and bookkeeping (such as, knowing which key to use for which resource). Secondly, when access to a resource is withdrawn from a certain application, new keys must be generated, distributed to all applications with access to that resource, and the resource must be re-encrypted. All of this makes that symmetric key encryption is a bad fit for this requirement.

%On the other hand, in chapter \ref{cha:analysis}, an analysis was made of \acrfull{ABE}. \Gls{ABE} could be a very effective method of reaching the stated goals; although some extra infrastructure would be required. Specifically, \gls{CP-ABE} offers many advantages in this context. First of all, key management is relatively straightforward. Because attributes are stored in private keys, every application only requires a single key per user. The access policies are independent of the distributed keys, facilitating key distribution. Secondly, \gls{CP-ABE} allows for very complex access policies per resource using threshold gates of attributes. These access policies are stored directly in the ciphertext, minimising their bookkeeping. Thirdly, the access policies can also be made dynamic. When the access requirements of a resource change, only the resource has to be re-encrypted with its new access policy. The private keys of all the applications do not need to be changed. However, because of the decentralized nature of \middleware{}, there are still some security challenges left. This section introduces a possible solution, which future research could investigate, extend, implement, and evaluate. This solution consists of a number of different phases, partially corresponding to the phases present in \gls{ABE}.

%\textbf{Setup phase}
%First, a security parameter is taken in, and a master and public key are generated. This public key is used for encrypting resources, the master key is used for generating private keys in the next step. 

%In the second part of the setup phase, a private key is generated for every trusted client application. This step takes as input the public key, the master key, and a set of attributes that should be assigned to the client application. This step is then repeated for every trusted client application.

%In the third step of the setup phase, the access policies are created. This part of the setup phase requires as input a mapping of resources to access policies. These access policies are embedded in the ciphertext of encrypted resources, and determine which attributes a private key must contain in order for it to be able to decrypt the ciphertext. Since these access policies can be subject to change, applications must request them before using these to encrypt a resource. However, this also introduces a possible vulnerability: if the access policies are stored in plaintext on the server, a malicious actor could modify them to make them trivially satisfied. Therefore, the access policies should bear some sort of digital signature, to attest their authenticity. Similarly, the public key should also bear the signature of a Certificate Authority, similar to SSL certificates, to allow clients to verify the authenticity of the public key. When these access policies are created for every resource, the resources are encrypted using the public key and the generated access policy.

%After the setup phase is completed, the master key is handed over to the user, after which it is destroyed. 

%\textbf{Key distribution}
%Once the setup phase has finished, the Solid server has a number of private keys (one per client application). It is unsafe to store them on the untrusted Solid server. Therefore, the first time a client application connects to the Solid server, the client application must first fetch the private key. Afterwards, it is destroyed from the Solid server, making sure that in case of a breach no keys are leaked. This means that there is a certain time period when the Solid server is still vulnerable to leaking data of the user. However, typically, there is no time period when both data and the private key are stored on the Solid server. As such, the only real risk is when a breach goes undetected for a while. In this scenario, an attacker could read the private keys, and after a while when data starts flowing in, decrypt this data. 

%\textbf{Encryption and decryption}
%Once the setup phase and key distribution have been completed, trusted applications can begin interacting with encrypted resource containers. When an application requests a resource, it will receive an encrypted representation of this resource. The application can then use its private key to decrypt this resource, if its key satisfies the access policy of the resource.

%On the other hand, encrypting resources is a bit more difficult. The encryption process has three inputs: the plaintext data, the public key and the access policy. The public key and access policy must be fetched from the Solid server where the resource will be stored. When the public key is fetched, the client application can verify its authenticity by checking that it has been digitally signed by a trusted Certificate Authority. It must then also verify the authenticity of the access policy. This can be done by decrypting the encrypted access policy, with a public key that it received. In this manner, it can verify that the access policy was encrypted with a private key, and as such that it is authentic. It can then encrypt the resource locally, and finally send the encrypted resource to the Solid server.
\end{futurework}

